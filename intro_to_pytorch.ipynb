{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8926,  0.3402, -0.1147, -0.6123, -0.8730,  0.6684,  1.3236, -1.1168,\n",
       "          0.4431, -0.7569],\n",
       "        [-0.2740,  1.9594, -0.6148,  0.6652,  0.5511,  0.4143, -0.1515, -2.5105,\n",
       "         -0.9403,  2.8212],\n",
       "        [ 0.6243, -1.6435, -2.2211, -1.2318, -0.6780, -0.6687,  1.4460,  0.3210,\n",
       "          0.3048, -0.7103],\n",
       "        [ 0.0184, -0.3967,  0.0285, -0.5379, -1.0714, -1.1811, -0.5733, -0.0179,\n",
       "          0.2051, -0.7259],\n",
       "        [ 1.4044,  1.1295,  0.1276,  1.4306,  0.0793, -0.8703, -0.0091,  0.1527,\n",
       "          0.5755,  0.0463]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8926,  0.3402, -0.1147, -0.6123, -0.8730,  0.6684,  1.3236, -1.1168,\n",
       "          0.4431, -0.7569, -0.2740,  1.9594, -0.6148,  0.6652,  0.5511,  0.4143,\n",
       "         -0.1515, -2.5105, -0.9403,  2.8212,  0.6243, -1.6435, -2.2211, -1.2318,\n",
       "         -0.6780, -0.6687,  1.4460,  0.3210,  0.3048, -0.7103,  0.0184, -0.3967,\n",
       "          0.0285, -0.5379, -1.0714, -1.1811, -0.5733, -0.0179,  0.2051, -0.7259,\n",
       "          1.4044,  1.1295,  0.1276,  1.4306,  0.0793, -0.8703, -0.0091,  0.1527,\n",
       "          0.5755,  0.0463]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "In order for this to happen we need to declare our paramerers as Tensors with the requires_grad=True keyword. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**2+1).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12., 16., 20., 24.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6593, -0.3363, -0.4154],\n",
       "        [ 1.3267,  1.6052,  0.5395]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is another example\n",
    "x = torch.randn(2, 3)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.3483, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (x**2).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3185, -0.6727, -0.8308],\n",
       "        [ 2.6534,  3.2104,  1.0791]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.backward()\n",
    "x.grad # note, it is the same shape as x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation ($A\\cdot X+b$) of a $N \\times 5$ matrix into a $N \\times 3$ matrix, where N can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.2681,  0.1868, -0.0134, -0.1176, -0.1357],\n",
       "         [ 0.2060, -0.1925, -0.3116,  0.4162, -0.0517],\n",
       "         [-0.1400, -0.0727, -0.3023,  0.0409, -0.3126]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1835,  0.0524,  0.3289], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "[p for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.512537237675988"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.512537237675988"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.8035], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.4759], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.14937977668988\n",
      "1.022709393193479\n",
      "0.5383180748787523\n",
      "0.43344356814616414\n",
      "0.3544305809313429\n",
      "0.29366957831535584\n",
      "0.2469366062134012\n",
      "0.21099293365199118\n",
      "0.1833476212988924\n",
      "0.16208481645167463\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.8081], dtype=torch.float64, requires_grad=True) tensor([7.5616], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.6691]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.0384], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why?\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "x = torch.unsqueeze(x, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3292],\n",
      "        [-0.4649],\n",
      "        [-0.6941],\n",
      "        ...,\n",
      "        [-0.4598],\n",
      "        [-0.2403],\n",
      "        [-0.3131]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x1)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(98.4905, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "F.mse_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "x_val, y_val = gen_fake_data(1000, 3., 8.)\n",
    "x_val = torch.tensor(x_val).float().unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the \n",
    "# weights of\n",
    "# the model for us. Here we will use Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 98.796 valid loss 95.851\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n",
      "train loss 0.090 valid loss 0.086\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train() # some layers have different behavior during train/and evaluation\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # checking validation loss\n",
    "    model.eval()  # some layers have different behavior during train/and evaluation\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.9982]], requires_grad=True), Parameter containing:\n",
      "tensor([8.0014], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff205dc3150>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8);\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and val data\n",
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "x_val, y_val = gen_logistic_fake_data(1000, 1., 0.5)\n",
    "x_val = torch.tensor(x_val).float()\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.279 valid loss 1.155\n",
      "train loss 0.015 valid loss 0.015\n",
      "train loss 0.010 valid loss 0.011\n",
      "train loss 0.007 valid loss 0.008\n",
      "train loss 0.006 valid loss 0.007\n",
      "train loss 0.005 valid loss 0.006\n",
      "train loss 0.004 valid loss 0.005\n",
      "train loss 0.003 valid loss 0.005\n",
      "train loss 0.002 valid loss 0.004\n",
      "train loss 0.002 valid loss 0.004\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train()\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(y_hat), y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-18.8909,  18.9085]], requires_grad=True), Parameter containing:\n",
      "tensor([-9.4594], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take a vector back to numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10, 1., 0.5)\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.122741  ,   0.19566005],\n",
       "       [  6.1833034 ,  -6.8303604 ],\n",
       "       [ -8.404926  , -19.9767    ],\n",
       "       [  6.541304  ,  11.745924  ],\n",
       "       [ -8.046523  , -13.91099   ],\n",
       "       [ 14.32502   ,  10.492154  ],\n",
       "       [-12.88226   ,  13.885471  ],\n",
       "       [-12.953713  ,  -7.2117085 ],\n",
       "       [-19.711988  ,  -9.144359  ],\n",
       "       [-17.811853  ,   7.4456882 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Compute the accuracy of the validation logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
