{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8944,  0.5518,  1.3626, -1.6689, -1.0140,  0.0733, -0.9792, -0.4583,\n",
       "         -0.0214, -0.0328],\n",
       "        [ 2.1215,  0.7449, -1.3612, -0.6892, -1.9834,  0.3807, -0.4959,  0.6101,\n",
       "          0.0373,  0.9089],\n",
       "        [-0.6079, -0.9839, -0.9774, -1.3893, -0.2027,  0.2578, -0.1280, -1.3316,\n",
       "          0.8959, -0.0958],\n",
       "        [-0.4407, -1.7830,  1.1857, -1.1052, -0.0233, -1.2510, -1.0828, -0.1617,\n",
       "         -0.3731, -0.4148],\n",
       "        [ 0.6966, -0.5710, -0.8394, -0.3627, -0.4516,  0.5025, -1.9229, -0.7097,\n",
       "          1.2630,  0.6867]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8944,  0.5518,  1.3626, -1.6689, -1.0140,  0.0733, -0.9792, -0.4583,\n",
       "         -0.0214, -0.0328,  2.1215,  0.7449, -1.3612, -0.6892, -1.9834,  0.3807,\n",
       "         -0.4959,  0.6101,  0.0373,  0.9089, -0.6079, -0.9839, -0.9774, -1.3893,\n",
       "         -0.2027,  0.2578, -0.1280, -1.3316,  0.8959, -0.0958, -0.4407, -1.7830,\n",
       "          1.1857, -1.1052, -0.0233, -1.2510, -1.0828, -0.1617, -0.3731, -0.4148,\n",
       "          0.6966, -0.5710, -0.8394, -0.3627, -0.4516,  0.5025, -1.9229, -0.7097,\n",
       "          1.2630,  0.6867]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "In order for this to happen we need to declare our paramerers as Tensors with the requires_grad=True keyword. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**2+1).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12., 16., 20., 24.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3457, -0.1265, -0.3636],\n",
       "        [-0.8412, -1.7846,  0.8345]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is another example\n",
    "x = torch.randn(2, 3)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.8566, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (x**2).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6913, -0.2530, -0.7272],\n",
       "        [-1.6824, -3.5692,  1.6691]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.backward()\n",
    "x.grad # note, it is the same shape as x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation ($A\\cdot X+b$) of a $N \\times 5$ matrix into a $N \\times 3$ matrix, where N can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.3428,  0.2591,  0.4171, -0.3648, -0.3017],\n",
       "         [ 0.0378, -0.4412, -0.0914,  0.2509,  0.1077],\n",
       "         [ 0.3949, -0.1619,  0.3850, -0.0431,  0.2022]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.2571, -0.4346,  0.3673], requires_grad=True)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "[p for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXlElEQVR4nO3df7BtZX3f8feHHxEUk4AcFdGTKw3JyDBpoweqxlitjkWGgWo1YuMEM+gdLagxbRo76VRrGmNsOm2jVkIKo7YNQk2it/gDbdUQW7H34M8L1HJzvVyugBy9lPQOqFz49o+9sYfjOufuc+5ea+0f79fMnbN/PHvv78M5rO9+nue7npWqQpKktY7qOwBJ0mQyQUiSGpkgJEmNTBCSpEYmCElSo2P6DmCcTj755Nq2bVvfYUjS1Ljxxhu/U1ULTc/NVILYtm0by8vLfYchSVMjyW3rPecUkySpkQlCktSotQSR5MokdyfZteqxlye5KclDSZY2eO3eJF9P8pUkzhlJUg/aHEG8HzhnzWO7gJcC14/w+udX1d+oqnUTiSSpPa0tUlfV9Um2rXnsFoAkbX2sJGlMJnUNooBPJbkxyfaNGibZnmQ5yfLKykpH4UnS7JvUBPELVfV04MXAJUmeu17Dqrq8qpaqamlhobGUV5K0BROZIKrqjuHPu4E/A87uNyJJ2tielYNcvXMfe1YO9h3K2EzciXJJHgMcVVX/d3j7RcDbew5Lkta1Z+Ug573781RBAte+4TmctnBC32EdsTbLXK8CvgD8bJL9SS5O8pIk+4FnAR9Lct2w7ZOSfHz40icAn0/yVeB/Ah+rqk+2FackHamdew9QBfc/8CBVg/uzoM0qpleu89SfNbS9Azh3eHsP8NfbikuSxu2sbSeRwPHHHk0yuD8LJm6KSZKmzWkLJ3DtG57Dzr0HOGvbSTMxvQQmCEkai9MWTpiZxPCwiaxikiT1zwQhSWpkgpAkNTJBSJIamSAkSY1MEJKkRiYISVIjE4QkqZEJQpLUyAQhSWpkgpAkNTJBSJIamSAkSY1MEJKkRiYISVIjE4QkqVGb16S+MsndSXateuzlSW5K8lCSpQ1ee06SbyTZneQtbcUoSVpfmyOI9wPnrHlsF/BS4Pr1XpTkaOC9wIuBM4BXJjmjpRglaSR7Vg5y9c597Fk52HconWntkqNVdX2SbWseuwUgyUYvPRvYXVV7hm0/BFwA3NxKoJJ0GHtWDnLeuz9PFSRw7RueM3OXF20yiWsQpwK3r7q/f/hYoyTbkywnWV5ZWWk9OEnzZ+feA1TB/Q88SNXg/jyYxATRNLyo9RpX1eVVtVRVSwsLCy2GJWlenbXtJBI4/tijSQb350FrU0xHYD/wlFX3nwzc0VMsksRpCydw7Ruew869Bzhr20lzMb0Ek5kgdgKnJ3kq8C3gQuDv9xuSpHl32sIJc5MYHtZmmetVwBeAn02yP8nFSV6SZD/wLOBjSa4btn1Sko8DVNUh4FLgOuAW4JqquqmtOCVJzVK17vT+1FlaWqrl5eW+w5CkqZHkxqpqPC9tEhepJUkTwAQhSWpkgpAkNTJBSJIamSAkSY1MEJK0SfOycd8knignSRNrnjbucwQhqVWz9m17njbucwQhqTWz+G27jY379qwcnMh9nkwQ0pxr8+C0+tv28ccezc69BybqALgV4964b5KTqAlCmmNtH5xmdZvscW7cN8lJ1AQhzbG2D06jftue1CmWLkxyEjVBSHOsi4PT4b5ttzGKmaaEM8nXmjBBSHNsEg5O4x7FTPKc/nom9VoTJghpzvV9cBr3KGYcCWeaRiBtMkFI6tW4RzFHmnCmcQTSFhOEpN6NcxRzpAlnkquKutZagkhyJXAecHdVnTl87CTgamAbsBf4paq6p+G1DwJfH97dV1XntxWnpNlzJAlnkquKutbaJUeTPBc4CHxwVYJ4F3Cgqt6Z5C3AiVX1mw2vPVhVm/7teslRSeMwT2sQG11ytLURRFVdn2TbmocvAJ43vP0B4HPAjyQISfNnkg7KfS/cT4qu1yCeUFV3AlTVnUkev06745IsA4eAd1bVR9Z7wyTbge0Ai4uL445XUsv2rBzk41+/k/d8djchnS4MT1JSmkSTuki9WFV3JDkN+EySr1fVXzY1rKrLgcthMMXUZZCSjszDFUMPPPgQDzw4+N+3q4Vhq5UOr+vtvr+d5BSA4c+7mxpV1R3Dn3sYTEP9fFcBSurOwxVDDyeHY49OZwvD87Rt91Z1nSB2ABcNb18EfHRtgyQnJnnU8PbJwC8AN3cWoaTOrK4YOu7Yo3jTC07v7Ju81UqH12YV01UMFqRPBr4NvBX4CHANsAjsA15eVQeSLAGvq6rXJHk28IfAQwwS2L+pqitG+UyrmKTp0+c6gGsQG1cxtZYg+mCCkKTN2ShBeMlRSZs2a5cRVbNJrWKSNKGs/pkfjiAkbYrVP/PDBCFpU6z+mR9OMUnalEm4yJC6YYKQtGnuVTQfnGKSJDUyQUg6Ypa9zianmCQdEcteZ5cjCElHxLLX2WWCkHRELHudXU4xSToilr3OLhOEpCNm2Ws/2t6N1gQhSVOoi+IA1yAkaQp1URxggpA0dp4X0b4uigOcYpI0Vp4X0Y0uigNMEJLGavXUx/HHHs3OvQdMEC1puzig1SmmJFcmuTvJrlWPnZTk00luHf48cZ3XXjRsc2uSi9qMU9L4eF7E7Gj1mtRJngscBD5YVWcOH3sXcKCq3pnkLcCJVfWba153ErAMLAEF3Ag8o6ru2ejzvCa1NBnaLr/U+PR2Teqquh5Yu7R+AfCB4e0PAH+34aV/B/h0VR0YJoVPA+e0Fqg0Z9peRD5t4QRecdaiyWHK9bEG8YSquhOgqu5M8viGNqcCt6+6v3/42I9Ish3YDrC4uDjmUKXZ4yKyRjWpZa5peKxxLqyqLq+qpapaWlhYaDksafptpX7estX51McI4ttJThmOHk4B7m5osx943qr7TwY+10Fs0szb7CKyI4751UeC2AFcBLxz+POjDW2uA96xqsLpRcA/6SY8abZttn7estX51WqCSHIVg5HAyUn2A29lkBiuSXIxsA94+bDtEvC6qnpNVR1I8tvAzuFbvb2q3GReGpPN1M9btjq/Wi1z7ZplrlI7LFudXRuVuXomtaTDcjvv+TSpVUzSVLLaR7PEEYQ0Jlb7aNY4gpDGpIv9+aUumSCkMbHaR7PGKSZpTLrYn1/qkglCGiOrfTRLnGKSJDUyQUiSGpkgNBc8P0HaPNcgNPM8P0HaGkcQmnmenyBtjQlCM8/zE6StcYpJM6/P8xPcBVXTzAShudDH+QmufWjaHXaKKcmlq67sJmlEq9c+HnyoeO9nd09EFZUVXRrVKCOIJwI7k3wJuBK4rmbpKkNSSx5e+3jUMUfx/UMPce3X7uQTu+7qdSThqEabcdgRRFX9U+B04Arg1cCtSd6R5K9t9UOTvCnJriQ3Jfm1huefl+TeJF8Z/vtnW/0sqS8Pr32c93On/DBJ9FFFtXrEYEWXNmOkNYiqqiR3AXcBh4ATgQ8n+XRV/ePNfGCSM4HXAmcDPwA+meRjVXXrmqZ/UVXnbea9pUlz2sIJXPL8n+YTu+7qpYpq7Yjhfb/8dCu6NLLDJogkbwQuAr4D/HvgN6rqgSRHAbcCm0oQwNOAG6rqvuH7/znwEuBdm3wfaSr0WUW1esRw/LFHc9dffc8dZzWyUUYQJwMvrarbVj9YVQ8l2co3/F3A7yR5HHA/cC6w3NDuWUm+CtwB/KOqumkLnyVNhL52eW06B8QdZzWq9LHenORi4BLgIHAzcH9VvXnV8z8OPFRVB5OcC/zbqjp9nffaDmwHWFxcfMZtt93W1EyaW56LoY0kubGqlhqf67sgKck7gP1V9e82aLMXWKqq72z0XktLS7W83DQYkSQ12ShB9LLVRpLHD38uAi8Frlrz/BOTZHj7bAZxfrfrOCVpnvV1JvWfDNcgHgAuqap7krwOoKouA14GvD7JIQbrFBd67oUkdauXBFFVv9jw2GWrbr8HeE+nQUmSHsHdXCVJjUwQkqRGJghJUiMThCSpkQlCktTIBKFOeA0Cafp4RTm1bqNrEPS1DYTbT0iHZ4JQ69buKLpz7wFOWziht4vXeNEcaTROMal1TTuKAr1dvMaL5kijcQSh1q2+HsITf/y4Hx6Q10scbevrc6Vp0/turuPkbq6TrWlqB5jKNQjXMDQrNtrN1RGEOtO0FvGKsxZ7OcAeyUVzXMPQvHANQp2Zlakd1zA0LxxBqDN9Xpt5nGYl0UmHY4JQp2bhesizkuikwzFBqDOztLA7C4lOOhwThDrhwq40fVykVidc2JWmTy8JIsmbkuxKclOSX2t4Pkn+IMnuJF9L8vQ+4tT4uLArTZ/Op5iSnAm8Fjgb+AHwySQfq6pbVzV7MXD68N/fBN43/KkpNW8Lu7O03qL51ccaxNOAG6rqPoAkfw68BHjXqjYXAB+swWneNyT5ySSnVNWd3YercVlvYXfWDqaut2hW9JEgdgG/k+RxwP3AucDa/TFOBW5fdX//8LEfSRBJtgPbARYXF9uIVy2axYPpervXStOm8zWIqroF+D3g08Anga8Ch9Y0S9NL13m/y6tqqaqWFhYWxhqr2jeLi9eut2hW9FLmWlVXAFcAJHkHgxHCavuBp6y6/2Tgjm6iU5dm8WA6b+stml29JIgkj6+qu5MsAi8FnrWmyQ7g0iQfYrA4fa/rD7NpVg+mnkinWdDXiXJ/MlyDeAC4pKruSfI6gKq6DPg4g7WJ3cB9wK/2FKc6MA0H01lbSJdG0dcU0y82PHbZqtsFXNJpUNI6ZnEhXRqFZ1JLhzGLC+nSKEwQ2pQ9Kwe5euc+9qwc7DuUzsziQro0Cjfr08jWm2qZ9fn5WV1Ilw7HBKGRNZ0ABszF/Pw0LKRL4+YUk0bWNNXi/Lw0uxxBaGRNUy23H7iPBx8qHnXMUc7PSzPGBDEG456Dn+Q5/dVTLXtWDvL6//QlEqgq3vfLz5i4eCVtnQniCI27Rn6aau4fnl76/qGHOP7Yo7nrr77Xd0iSxsg1iCM07jn4aZrTt/xTmm2OII7QuA+S03TQtfxTmm0Z7GoxG5aWlmp5ee2lJdo3T2sQkmZLkhuraqnpOUcQYzDuGvmN3s/kIakrJogt6uNAPU0L2JKmnwliC/o6UHspS0ldsoppC/qqNJqmBWxJ088RxBb0daC2akhSl0wQW9DngdpN4yR1xQSxRR6oJc26XtYgkrw5yU1JdiW5Kslxa55/dZKVJF8Z/ntNH3GqXfN48SFpmnQ+gkhyKvBG4Iyquj/JNcCFwPvXNL26qi7tOj51w5JdafL1VcV0DHB8kmOARwN39BRHJ/r4pjzp386nac8paV51PoKoqm8l+X1gH3A/8Kmq+lRD07+X5LnA/wbeXFW3N71fku3AdoDFxcWWot66cX5THvXkvGn4dm7JrjT5Oh9BJDkRuAB4KvAk4DFJXrWm2X8BtlXVzwH/FfjAeu9XVZdX1VJVLS0sLLQV9paN65vywwf9t+24mfPe/fkNRwbT8O384Uqwt51/xkQmMEn9TDG9EPhmVa1U1QPAnwLPXt2gqr5bVd8f3v0j4Bkdxzg24/qmvJmD/rR8Oz9t4QRecdaiyUGaUH2Uue4Dnpnk0QymmF4APGIL1iSnVNWdw7vnA7d0G+L4jOucic0c9D2hTtI49LLdd5J/DrwCOAR8GXgN8FvAclXtSPK7DBLDIeAA8Pqq+l+He9++tvvuSlcbBLpjrDQ/Ntru2+tB6BGmYYFb0vhslCDcrE+PMA0L3JK6YYKYUm2d5zAtC9yS2udeTFOozWkgF7glPcwEMYXavnCQGxFKAqeYppLTQJK64AhiCjkNJKkLJogp5TSQpLY5xSRJamSCWGXSt8iWpC45xTTkGcSS9EiOIIY8g1iSHskEMWTpqCQ9klNMQ5aOStIjmSBWsXRUkv4/p5g2YFWTpHnmCGIdVjVJmneOINZhVZOkeddLgkjy5iQ3JdmV5Kokx615/lFJrk6yO8kXk2zrOkarmiTNu86nmJKcCrwROKOq7k9yDXAh8P5VzS4G7qmqn05yIfB7DK5h3RmrmiTNu77WII4Bjk/yAPBo4I41z18AvG14+8PAe5KkOr6AtlVNkuZZ51NMVfUt4PeBfcCdwL1V9ak1zU4Fbh+2PwTcCzyu6f2SbE+ynGR5ZWWlvcAlac50niCSnMhghPBU4EnAY5K8am2zhpc2jh6q6vKqWqqqpYWFhfEGOwMs1ZW0VX1MMb0Q+GZVrQAk+VPg2cB/XNVmP/AUYH+SY4CfACwj2iRLdSUdiT6qmPYBz0zy6CQBXgDcsqbNDuCi4e2XAZ/pev1hFliqK+lI9LEG8UUGC89fAr4+jOHyJG9Pcv6w2RXA45LsBn4deEvXcc4CS3UlHYnM0hfzpaWlWl5e7juMibJn5aClupLWleTGqlpqes6tNmacpbqStsqtNiRJjUwQkqRGJghJUiMThCSpkQlCktTIBCFJamSCGHLPIkl6JM+DwD2LJKmJIwjcs0iSmpggcM8iSWriFBNeXlSSmpgghtyzSJIeySkmSVIjE4QkqZEJQpLUyAQhSWpkgpAkNTJBSJIazdQ1qZOsALet8/TJwHc6DGeSzGvf57XfML99n9d+w9b7/lNVtdD0xEwliI0kWV7vwtyzbl77Pq/9hvnt+7z2G9rpu1NMkqRGJghJUqN5ShCX9x1Aj+a17/Pab5jfvs9rv6GFvs/NGoQkaXPmaQQhSdoEE4QkqdHMJYgk5yT5RpLdSd7S8Pyjklw9fP6LSbZ1H2U7Ruj7rye5OcnXkvy3JD/VR5zjdrh+r2r3siSVZCbKIEfpd5JfGv7Ob0ryx13H2JYR/tYXk3w2yZeHf+/n9hHnuCW5MsndSXat83yS/MHwv8vXkjz9iD6wqmbmH3A08JfAacCPAV8FzljT5h8Alw1vXwhc3XfcHfb9+cCjh7dfPwt9H6Xfw3aPBa4HbgCW+o67o9/36cCXgROH9x/fd9wd9v1y4PXD22cAe/uOe0x9fy7wdGDXOs+fC3wCCPBM4ItH8nmzNoI4G9hdVXuq6gfAh4AL1rS5APjA8PaHgRckSYcxtuWwfa+qz1bVfcO7NwBP7jjGNozyOwf4beBdwPe6DK5Fo/T7tcB7q+oegKq6u+MY2zJK3wv48eHtnwDu6DC+1lTV9cCBDZpcAHywBm4AfjLJKVv9vFlLEKcCt6+6v3/4WGObqjoE3As8rpPo2jVK31e7mME3jWl32H4n+XngKVV1bZeBtWyU3/fPAD+T5L8nuSHJOZ1F165R+v424FVJ9gMfB97QTWi92+xxYEOzdsnRppHA2jreUdpMo5H7leRVwBLwt1qNqBsb9jvJUcC/Bl7dVUAdGeX3fQyDaabnMRgt/kWSM6vq/7QcW9tG6fsrgfdX1b9K8izgPwz7/lD74fVqrMe3WRtB7Aeesur+k/nRoeUP2yQ5hsHwc6Mh27QYpe8keSHwW8D5VfX9jmJr0+H6/VjgTOBzSfYymJfdMQML1aP+rX+0qh6oqm8C32CQMKbdKH2/GLgGoKq+ABzHYDO7WTfScWBUs5YgdgKnJ3lqkh9jsAi9Y02bHcBFw9svAz5Tw9WdKXfYvg+nWv6QQXKYlfnoDftdVfdW1clVta2qtjFYezm/qpb7CXdsRvlb/wiDwgSSnMxgymlPp1G2Y5S+7wNeAJDkaQwSxEqnUfZjB/Arw2qmZwL3VtWdW32zmZpiqqpDSS4FrmNQ6XBlVd2U5O3AclXtAK5gMNzczWDkcGF/EY/PiH3/l8AJwH8ersvvq6rzewt6DEbs98wZsd/XAS9KcjPwIPAbVfXd/qIejxH7/g+BP0ryZgZTLK+ehS+CSa5iMGV48nB95a3AsQBVdRmD9ZZzgd3AfcCvHtHnzcB/M0lSC2ZtikmSNCYmCElSIxOEJKmRCUKS1MgEIUlqZIKQJDUyQUiSGpkgpJYkOWu4J/9xSR4zvCbDmX3HJY3KE+WkFiX5Fwy2eTge2F9Vv9tzSNLITBBSi4Z7Be1kcB2KZ1fVgz2HJI3MKSapXScx2P/qsQxGEtLUcAQhtSjJDgZXPHsqcEpVXdpzSNLIZmo3V2mSJPkV4FBV/XGSo4H/keRvV9Vn+o5NGoUjCElSI9cgJEmNTBCSpEYmCElSIxOEJKmRCUKS1MgEIUlqZIKQJDX6f9Y4p0NQhcttAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8922458219828724"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8922458219828724"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-1.2238], dtype=torch.float64, requires_grad=True),\n",
       " tensor([1.6056], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.97854356875074\n",
      "0.5732956082190388\n",
      "0.11201981486475934\n",
      "0.10476574280217496\n",
      "0.10134422416115176\n",
      "0.09872679066977735\n",
      "0.09671432202072992\n",
      "0.09516692994446566\n",
      "0.09397713599169187\n",
      "0.09306230020085071\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.8355], dtype=torch.float64, requires_grad=True) tensor([8.0854], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.5985]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3208], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why?\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(5000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 1])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "x = torch.unsqueeze(x, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0057],\n",
      "        [-0.0057],\n",
      "        [-0.2378],\n",
      "        ...,\n",
      "        [-0.1218],\n",
      "        [ 0.1016],\n",
      "        [ 0.0454]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(91.4310, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "F.mse_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "x_val, y_val = gen_fake_data(1000, 3., 8.)\n",
    "x_val = torch.tensor(x_val).float().unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the \n",
    "# weights of\n",
    "# the model for us. Here we will use Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 91.431 valid loss 88.627\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n",
      "train loss 0.090 valid loss 0.092\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train() # some layers have different behavior during train/and evaluation\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # checking validation loss\n",
    "    model.eval()  # some layers have different behavior during train/and evaluation\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[3.0081]], requires_grad=True), Parameter containing:\n",
      "tensor([7.9990], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e9cc3d0>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8);\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and val data\n",
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "x_val, y_val = gen_logistic_fake_data(1000, 1., 0.5)\n",
    "x_val = torch.tensor(x_val).float()\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.169 valid loss 1.099\n",
      "train loss 0.015 valid loss 0.013\n",
      "train loss 0.010 valid loss 0.008\n",
      "train loss 0.008 valid loss 0.006\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train()\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(y_hat), y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-18.8909,  18.9085]], requires_grad=True), Parameter containing:\n",
      "tensor([-9.4594], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take a vector back to numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10, 1., 0.5)\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.122741  ,   0.19566005],\n",
       "       [  6.1833034 ,  -6.8303604 ],\n",
       "       [ -8.404926  , -19.9767    ],\n",
       "       [  6.541304  ,  11.745924  ],\n",
       "       [ -8.046523  , -13.91099   ],\n",
       "       [ 14.32502   ,  10.492154  ],\n",
       "       [-12.88226   ,  13.885471  ],\n",
       "       [-12.953713  ,  -7.2117085 ],\n",
       "       [-19.711988  ,  -9.144359  ],\n",
       "       [-17.811853  ,   7.4456882 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Compute the accuracy of the validation logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
