{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7151, -1.2249,  0.3608,  0.2748,  0.5088,  0.2146,  1.3497,  0.0113,\n",
       "          0.3929, -1.5933],\n",
       "        [ 0.7657,  0.1487,  1.2640,  1.0226, -1.0406,  1.3103,  1.7733, -0.9435,\n",
       "          0.5921, -1.3779],\n",
       "        [-2.0844,  0.5154,  0.0534,  1.0516,  0.4533, -1.1083,  2.1071,  0.1926,\n",
       "          3.1287,  1.1568],\n",
       "        [ 2.3634, -0.7956,  0.2568,  0.4804, -0.9440, -0.3169, -0.3819, -0.7790,\n",
       "          2.3947, -1.2116],\n",
       "        [ 0.7115,  0.9129, -0.0727,  0.6320,  0.4845, -1.7476, -0.3179,  1.2758,\n",
       "         -0.5407,  2.0949]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7151, -1.2249,  0.3608,  0.2748,  0.5088,  0.2146,  1.3497,  0.0113,\n",
       "          0.3929, -1.5933,  0.7657,  0.1487,  1.2640,  1.0226, -1.0406,  1.3103,\n",
       "          1.7733, -0.9435,  0.5921, -1.3779, -2.0844,  0.5154,  0.0534,  1.0516,\n",
       "          0.4533, -1.1083,  2.1071,  0.1926,  3.1287,  1.1568,  2.3634, -0.7956,\n",
       "          0.2568,  0.4804, -0.9440, -0.3169, -0.3819, -0.7790,  2.3947, -1.2116,\n",
       "          0.7115,  0.9129, -0.0727,  0.6320,  0.4845, -1.7476, -0.3179,  1.2758,\n",
       "         -0.5407,  2.0949]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "In order for this to happen we need to declare our paramerers as Tensors with the requires_grad=True keyword. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**2+1).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12., 16., 20., 24.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation ($A\\cdot X+b$) of a $N \\times 5$ matrix into a $N \\times 3$ matrix, where N can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0054, -0.2242, -0.2035,  0.3029,  0.4171],\n",
       "         [ 0.1174, -0.4459,  0.3495, -0.0725, -0.4081],\n",
       "         [ 0.1489, -0.2053,  0.0349,  0.3322,  0.2839]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3251,  0.3250, -0.4193], requires_grad=True)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "[p for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.888533690451327"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.888533690451327"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.5898], dtype=torch.float64, requires_grad=True),\n",
       " tensor([-1.4499], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114.12321442713517\n",
      "1.0779056876879545\n",
      "0.30909755869765704\n",
      "0.2551177379586183\n",
      "0.21697536719705732\n",
      "0.18767915381015465\n",
      "0.16516155402849003\n",
      "0.14785402012281942\n",
      "0.1345510594729575\n",
      "0.12432610408167993\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5443], dtype=torch.float64, requires_grad=True) tensor([7.7089], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.9189]], requires_grad=True), Parameter containing:\n",
      "tensor([0.7947], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why?\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "x1 = torch.unsqueeze(x, 1)\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8188],\n",
      "        [1.0345],\n",
      "        [0.8765],\n",
      "        ...,\n",
      "        [1.2144],\n",
      "        [1.6932],\n",
      "        [1.0558]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x1)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the \n",
    "# weights of\n",
    "# the model for us. Here we will use Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.34102630615234\n",
      "0.09136968851089478\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n",
      "0.09136949479579926\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    y_hat = model(x1)\n",
    "    loss = F.mse_loss(y_hat, y.unsqueeze(1))\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[3.0134]], requires_grad=True), Parameter containing:\n",
      "tensor([7.9910], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe451a2a7d0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8);\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.100495338439941\n",
      "0.016775736585259438\n",
      "0.011402207426726818\n",
      "0.008742752484977245\n",
      "0.007029195316135883\n",
      "0.005791353527456522\n",
      "0.00484353955835104\n",
      "0.004093777853995562\n",
      "0.0034880321472883224\n",
      "0.002989949192851782\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(y_hat), y.unsqueeze(1))\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-17.0366,  17.0376]], requires_grad=True), Parameter containing:\n",
      "tensor([-8.5790], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Data loaders "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all of deep learning is powered by one very important algorithm: **stochastic gradient descent (SGD)**. SGD can be seeing as an approximation of **gradient descent** (GD). In GD you have to run through *all* the samples in your training set to do a single itaration. In SGD you use *only one* or *a subset*  of training samples to do the update for a parameter in a particular iteration. The subset use in every iteration is called a **batch** or **minibatch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(1, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x.astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "# create a dataset\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, a=3, b=8, n=10000):\n",
    "        x, y = gen_fake_data(n, a, b)\n",
    "        x = torch.from_numpy(x).unsqueeze(1)\n",
    "        y = torch.from_numpy(y)\n",
    "        self.x, self.y = x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    \n",
    "fake_dataset = RegressionDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we are going to create a data loader. The data loader provides the following features:\n",
    "* Batching the data\n",
    "* Shuffling the data\n",
    "* Load the data in parallel using multiprocessing workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(fake_dataset, batch_size=1000, shuffle=True)\n",
    "x, y = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1000, 1]), torch.Size([1000]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.76058959960938\n",
      "0.11391273140907288\n",
      "0.0924905315041542\n",
      "0.0860438272356987\n"
     ]
    }
   ],
   "source": [
    "for t in range(200):\n",
    "    for i, (x, y) in enumerate(dataloader): \n",
    "        \n",
    "        y_hat = model2(x)\n",
    "        loss = F.mse_loss(y_hat, y.unsqueeze(1))\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    if t % 50 == 0: print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[ 2.9897]]), Parameter containing:\n",
      "tensor([ 8.0051])]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model2.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
