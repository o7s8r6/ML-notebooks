{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MNIST\n",
    "Here we load the dataset and create data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('../data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('../data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(train_loader)\n",
    "x, y = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper method (from fast.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(img, title=None):\n",
    "    plt.imshow(img, interpolation='none', cmap=\"gray\")\n",
    "    if title is not None: plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 1, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first from torch to numpy\n",
    "X = x.numpy(); Y = y.numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show(X[0][0], Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]\n",
      " [-0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296 -0.42421296\n",
      "  -0.42421296 -0.42421296 -0.42421296 -0.42421296]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][0][:4][:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the number of neurons in the hidden unit\n",
    "def get_model(M = 300):\n",
    "    net = nn.Sequential(nn.Linear(28*28, M),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(M, 10))\n",
    "    return net #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader, test_loader, num_epochs, model, optimizer):\n",
    "    model.train()\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):  \n",
    "            batch = images.shape[0] # size of the batch\n",
    "            # Convert torch tensor to Variable, change shape of the input\n",
    "            images = images.view(-1, 28*28) #.cuda()\n",
    "        \n",
    "            # Forward + Backward + Optimize\n",
    "            optimizer.zero_grad()  # zero the gradient buffer\n",
    "            outputs = model(images)\n",
    "            loss = F.cross_entropy(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "            total += batch\n",
    "            sum_loss += batch * loss.item()\n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, sum_loss/total))\n",
    "                \n",
    "        train_loss = sum_loss/total\n",
    "        print('Epoch [%d/%d], Loss: %.4f' %(epoch+1, num_epochs, train_loss))\n",
    "        val_acc, val_loss = model_accuracy_loss(model, test_loader)\n",
    "        print('Epoch [%d/%d], Valid Accuracy: %.4f, Valid Loss: %.4f' %(epoch+1, num_epochs, val_acc, val_loss))\n",
    "    return val_acc, val_loss, train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy_loss(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    sum_loss = 0.0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.view(-1, 28*28)  #.cuda()\n",
    "        outputs = model(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        sum_loss += labels.size(0)*loss.item()\n",
    "        total += labels.size(0)\n",
    "        correct += pred.eq(labels.data).sum().item()\n",
    "    return 100 * correct / total, sum_loss/ total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.81, 2.3784399974822996)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_model()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "model_accuracy_loss(net, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Loss: 0.7367\n",
      "Epoch [1/2], Loss: 0.5800\n",
      "Epoch [1/2], Loss: 0.5059\n",
      "Epoch [1/2], Loss: 0.4693\n",
      "Epoch [1/2], Loss: 0.4492\n",
      "Epoch [1/2], Loss: 0.4312\n",
      "Epoch [1/2], Loss: 0.4131\n",
      "Epoch [1/2], Loss: 0.4034\n",
      "Epoch [1/2], Loss: 0.3937\n",
      "Epoch [1/2], Loss: 0.3851\n",
      "Epoch [1/2], Loss: 0.3775\n",
      "Epoch [1/2], Loss: 0.3735\n",
      "Epoch [1/2], Loss: 0.3670\n",
      "Epoch [1/2], Loss: 0.3632\n",
      "Epoch [1/2], Loss: 0.3582\n",
      "Epoch [1/2], Loss: 0.3565\n",
      "Epoch [1/2], Loss: 0.3557\n",
      "Epoch [1/2], Loss: 0.3512\n",
      "Epoch [1/2], Loss: 0.3473\n",
      "Epoch [1/2], Valid Accuracy: 92.8500, Valid Loss: 0.2543\n",
      "Epoch [2/2], Loss: 0.3422\n",
      "Epoch [2/2], Loss: 0.3386\n",
      "Epoch [2/2], Loss: 0.3355\n",
      "Epoch [2/2], Loss: 0.3329\n",
      "Epoch [2/2], Loss: 0.3297\n",
      "Epoch [2/2], Loss: 0.3273\n",
      "Epoch [2/2], Loss: 0.3253\n",
      "Epoch [2/2], Loss: 0.3229\n",
      "Epoch [2/2], Loss: 0.3201\n",
      "Epoch [2/2], Loss: 0.3190\n",
      "Epoch [2/2], Loss: 0.3165\n",
      "Epoch [2/2], Loss: 0.3156\n",
      "Epoch [2/2], Loss: 0.3143\n",
      "Epoch [2/2], Loss: 0.3141\n",
      "Epoch [2/2], Loss: 0.3139\n",
      "Epoch [2/2], Loss: 0.3131\n",
      "Epoch [2/2], Loss: 0.3122\n",
      "Epoch [2/2], Loss: 0.3116\n",
      "Epoch [2/2], Loss: 0.3106\n",
      "Epoch [2/2], Valid Accuracy: 92.0700, Valid Loss: 0.3064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(92.07, 0.3064056280315854, 0.31058098874678836)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=2, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with L2 regularization\n",
    "To add L2 regularization use the `weight_decay` argument on the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_v2(M = 300, p=0):\n",
    "    modules = []\n",
    "    modules.append(nn.Linear(28*28, M))\n",
    "    modules.append(nn.ReLU())\n",
    "    if p > 0:\n",
    "        modules.append(nn.Dropout(p))\n",
    "    modules.append(nn.Linear(M, 10))\n",
    "    return nn.Sequential(*modules) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = get_model_v2(M = 300, p=0.1)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Loss: 0.7627\n",
      "Epoch [1/4], Loss: 0.6168\n",
      "Epoch [1/4], Loss: 0.5430\n",
      "Epoch [1/4], Loss: 0.5011\n",
      "Epoch [1/4], Loss: 0.4805\n",
      "Epoch [1/4], Loss: 0.4698\n",
      "Epoch [1/4], Loss: 0.4667\n",
      "Epoch [1/4], Loss: 0.4585\n",
      "Epoch [1/4], Loss: 0.4471\n",
      "Epoch [1/4], Loss: 0.4396\n",
      "Epoch [1/4], Loss: 0.4325\n",
      "Epoch [1/4], Loss: 0.4326\n",
      "Epoch [1/4], Loss: 0.4291\n",
      "Epoch [1/4], Loss: 0.4299\n",
      "Epoch [1/4], Loss: 0.4272\n",
      "Epoch [1/4], Loss: 0.4255\n",
      "Epoch [1/4], Loss: 0.4235\n",
      "Epoch [1/4], Loss: 0.4211\n",
      "Epoch [1/4], Loss: 0.4221\n",
      "Epoch [1/4], Valid Accuracy: 92.2300, Valid Loss: 0.3075\n",
      "Epoch [2/4], Loss: 0.4151\n",
      "Epoch [2/4], Loss: 0.4074\n",
      "Epoch [2/4], Loss: 0.4015\n",
      "Epoch [2/4], Loss: 0.3965\n",
      "Epoch [2/4], Loss: 0.3896\n",
      "Epoch [2/4], Loss: 0.3862\n",
      "Epoch [2/4], Loss: 0.3818\n",
      "Epoch [2/4], Loss: 0.3772\n",
      "Epoch [2/4], Loss: 0.3740\n",
      "Epoch [2/4], Loss: 0.3702\n",
      "Epoch [2/4], Loss: 0.3679\n",
      "Epoch [2/4], Loss: 0.3638\n",
      "Epoch [2/4], Loss: 0.3622\n",
      "Epoch [2/4], Loss: 0.3597\n",
      "Epoch [2/4], Loss: 0.3571\n",
      "Epoch [2/4], Loss: 0.3544\n",
      "Epoch [2/4], Loss: 0.3528\n",
      "Epoch [2/4], Loss: 0.3504\n",
      "Epoch [2/4], Loss: 0.3493\n",
      "Epoch [2/4], Valid Accuracy: 91.8500, Valid Loss: 0.3173\n",
      "Epoch [3/4], Loss: 0.3462\n",
      "Epoch [3/4], Loss: 0.3440\n",
      "Epoch [3/4], Loss: 0.3412\n",
      "Epoch [3/4], Loss: 0.3381\n",
      "Epoch [3/4], Loss: 0.3365\n",
      "Epoch [3/4], Loss: 0.3355\n",
      "Epoch [3/4], Loss: 0.3348\n",
      "Epoch [3/4], Loss: 0.3344\n",
      "Epoch [3/4], Loss: 0.3318\n",
      "Epoch [3/4], Loss: 0.3299\n",
      "Epoch [3/4], Loss: 0.3279\n",
      "Epoch [3/4], Loss: 0.3261\n",
      "Epoch [3/4], Loss: 0.3248\n",
      "Epoch [3/4], Loss: 0.3245\n",
      "Epoch [3/4], Loss: 0.3231\n",
      "Epoch [3/4], Loss: 0.3221\n",
      "Epoch [3/4], Loss: 0.3208\n",
      "Epoch [3/4], Loss: 0.3205\n",
      "Epoch [3/4], Loss: 0.3208\n",
      "Epoch [3/4], Valid Accuracy: 92.7700, Valid Loss: 0.2811\n",
      "Epoch [4/4], Loss: 0.3188\n",
      "Epoch [4/4], Loss: 0.3177\n",
      "Epoch [4/4], Loss: 0.3160\n",
      "Epoch [4/4], Loss: 0.3145\n",
      "Epoch [4/4], Loss: 0.3133\n",
      "Epoch [4/4], Loss: 0.3126\n",
      "Epoch [4/4], Loss: 0.3124\n",
      "Epoch [4/4], Loss: 0.3113\n",
      "Epoch [4/4], Loss: 0.3102\n",
      "Epoch [4/4], Loss: 0.3094\n",
      "Epoch [4/4], Loss: 0.3081\n",
      "Epoch [4/4], Loss: 0.3077\n",
      "Epoch [4/4], Loss: 0.3070\n",
      "Epoch [4/4], Loss: 0.3068\n",
      "Epoch [4/4], Loss: 0.3064\n",
      "Epoch [4/4], Loss: 0.3056\n",
      "Epoch [4/4], Loss: 0.3054\n",
      "Epoch [4/4], Loss: 0.3050\n",
      "Epoch [4/4], Loss: 0.3046\n",
      "Epoch [4/4], Valid Accuracy: 93.9200, Valid Loss: 0.2919\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(93.92, 0.2919134729707148, 0.3045825398512709)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(train_loader, test_loader, num_epochs=4, model=net, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
